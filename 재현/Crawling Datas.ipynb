{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* our team crawled data from sites Dabang(this is code to run on the ubuntu enviroment)\n",
    "\n",
    " * Save every data in  MongoDB\n",
    " * 1st saved all the urls of the site where we can find the information of individual room near the universities in Seoul python pacakge Selenium\n",
    " * By using Selenium package we inserted universities names in the search box\n",
    "![GitHub Logo](image1.png) \n",
    " * Also we can turn to the next page\n",
    "![GitHub Logo](image2.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "from pymongo import MongoClient\n",
    "from selenium import webdriver\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Href_Scretcher_Dabang(object):\n",
    "    \n",
    "    def __init__(self, university_lst):\n",
    "        self.university_lst = university_lst\n",
    "    \n",
    "       \n",
    "    def extract_href(self):\n",
    "        href_lst = []\n",
    "        driver = webdriver.Chrome('./chromedriver')\n",
    "        driver.get('https://www.dabangapp.com/search#/map')\n",
    "        for i in self.university_lst:\n",
    "            # Insert university name in the search_box\n",
    "            try:\n",
    "                text_box = driver.find_element_by_xpath(\"//input[@class='SearchForm-input form-control']\")\n",
    "                text_box.clear()\n",
    "                address =  i\n",
    "                address = address.decode('utf8')\n",
    "                text_box.send_keys(address)\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                continue\n",
    "            # Click the box if the name we insert matched    \n",
    "            try:\n",
    "                click_box = driver.find_element_by_xpath('''//ul[@class='SearchForm-list search-items']/li/span[@class='SearchForm-item name full']''')\n",
    "                text = click_box.text\n",
    "            except:\n",
    "                print 'text_error' \n",
    "            if address in text:    \n",
    "                click_box.click() \n",
    "            else:\n",
    "                print 'not match'\n",
    "                continue    \n",
    "            # Wait untill page loaded successfully\n",
    "            time.sleep(3)\n",
    "            try:\n",
    "                region_box = driver.find_elements_by_class_name(\"Room-item\")\n",
    "                # added all the urls  \n",
    "                for i,room_info in enumerate(region_box):\n",
    "                    try:\n",
    "                        link = room_info.find_element_by_tag_name('a')\n",
    "                        href = link.get_attribute('href')\n",
    "                        href_lst.append(href)\n",
    "                    except:\n",
    "                        print 'no a tag with href'                \n",
    "                        \n",
    "                while True:\n",
    "                    try:\n",
    "                        time.sleep(3)\n",
    "                        # find the next icon to turn to the next pages\n",
    "                        next_icon = driver.find_element_by_xpath(\"//ul[@class='Pagination']//a[@class='Pagination-item Pagination-item--next']\")\n",
    "                        next_icon.click()\n",
    "                        region_box = driver.find_elements_by_class_name(\"Room-item\")\n",
    "                        for i,room_info in enumerate(region_box):\n",
    "                            try:\n",
    "                                link = room_info.find_element_by_tag_name('a')\n",
    "                                href = link.get_attribute('href')\n",
    "                                href_lst.append(href)\n",
    "                            except:\n",
    "                                print 'no a tag with href'\n",
    "                                continue\n",
    "                    #If there is no active next icon break from the loop    \n",
    "                    except: \n",
    "                        print 'no next icon'\n",
    "                        break\n",
    "\n",
    "                    \n",
    "            \n",
    "            except:\n",
    "                print 'Nothing to do'\n",
    "        driver.quit()\n",
    "        return href_lst\n",
    "    \n",
    "    def extract_final_lst(self):\n",
    "        href_lst = self.extract_href()\n",
    "        href_lst = set(href_lst)\n",
    "        self.final_lst = list(href_lst)\n",
    "        return final_lst\n",
    "    \n",
    "    def href_to_mongo(self):\n",
    "        mongo = MongoClient('Your Mongo DB Repository', 27017)\n",
    "        database = mongo.Dabang.urls\n",
    "        href_data = []\n",
    "        st = set()\n",
    "        # insert the new url that is not found in the Mongo DB\n",
    "        for i in database.find():\n",
    "            st.add(i['url'])\n",
    "        for i in self.final_lst:\n",
    "            url = {}\n",
    "            if i in st:\n",
    "                continue\n",
    "            url['url'] = i\n",
    "            href_data.append(url)\n",
    "        database.insert_many(href_data)\n",
    "        \n",
    "    # Function to write the collected data to the textfile     \n",
    "    def write_file(self, file_name):\n",
    "        with open(file_name,'w') as txtfile:\n",
    "            for i in self.final_lst:\n",
    "                url = i + ' '\n",
    "                txtfile.write(url)\n",
    "print 'start'\n",
    "u_lst = ['서울교육대학교', '서울대학교', '서울과학기술대학교','육군사관학교','한국방송통신대학교',\n",
    " '한국예술종합학교','한국체육대학교','KAIST','서울시립대학교','가톨릭대학교','감리교신학대학교',\n",
    " '건국대학교','경기대학교','경희대학교','고려대학교','광운대학교','국민대학교','그리스도대학교',\n",
    " '덕성여자대학교','동국대학교','동덕여자대학교','명지대학교','삼육대학교','상명대학교',\n",
    " '서강대학교','서경대학교','서울기독대학교','서울여자대학교','성공회대학교','성균관대학교',\n",
    " '성신여자대학교','세종대학교','숙명여자대학교','숭실대학교','연세대학교','이화여자대학교',\n",
    " '장로회신학대학교','중앙대학교','총신대학교','추계예술대학교','한국성서대학교',\n",
    " '한국외국어대학교','한성대학교','한양대학교','한영신학대학교','홍익대학교']\n",
    "dabang = Href_Scretcher_Dabang(u_lst)\n",
    "dabang.extract_final_lst()\n",
    "dabang.href_to_mongo()\n",
    "print 'Sucess'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After we have stored all the urls in to the MongoDB we extract those datas and tried to insert the informations in the room_db collection that we can extract from each urls\n",
    "* When we requested the data in url we could finded that the room informations were stored in the jsonformat like dabang.web.detail({json format})\n",
    "![GitHub Logo](image4.png) \n",
    "\n",
    "* After parsing these format with regular expression we could store all the data easily into MongoDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "\n",
    "        \n",
    "def href_to_mongodb():\n",
    "    mongo = MongoClient('Your Mongo DB Repository', 27017)\n",
    "    hrefbase = mongo.Dabang.urls\n",
    "    house_info = mongo.Dabang.room_db\n",
    "    duplicated = set() \n",
    "    # Find the list of house price web page which were alreday inserted in the Database\n",
    "    try:\n",
    "        for i in house_info.find():\n",
    "            duplicated.add('https://www.dabangapp.com/room/'+ i['id'])\n",
    "    # If there is no data in the house info DB return duplicated set as empty\n",
    "    except:\n",
    "        duplicated = []\n",
    "\n",
    "    house_data = [] \n",
    "    for  href in  hrefbase.find():\n",
    "        if href['url'] in ls:\n",
    "            continue    \n",
    "        # Request information from the url\n",
    "        try:\n",
    "            web = requests.get(href['url'])\n",
    "            x = re.search('dabang.web.detail\\((.*}})',web.content) # Parsing the data that we need \n",
    "            jsonform = x.group(1) \n",
    "        except:\n",
    "            print \"Cannot get the information from url\"\n",
    "            continue\n",
    "        try:\n",
    "            jsonf = json.loads(jsonform) #Transform the data to json format\n",
    "        except:\n",
    "            continue\n",
    "        housedict = {}\n",
    "        housedict['id'] = jsonf['room']['id']\n",
    "        housedict['address']= jsonf['room']['address']\n",
    "        housedict['loc'] = (jsonf['room']['location'])\n",
    "        housedict['room_size'] = jsonf['room']['room_size']\n",
    "        housedict['room_floor'] = jsonf['room']['room_floor']\n",
    "        housedict['building_floor'] = jsonf['room']['building_floor']\n",
    "        housedict['room_options'] = jsonf['room']['room_options']\n",
    "        housedict['room_type'] = jsonf['room']['room_type_str']\n",
    "        try:\n",
    "            housedict['metro_count'] = jsonf['room']['near'][0]['total']\n",
    "            housedict['d_to_metro'] = min(jsonf['room']['near'][0]['pois'],key = itemgetter('distance'))['distance']\n",
    "            housedict['d_to_conv'] = min(jsonf['room']['near'][1]['pois'],key = itemgetter('distance'))['distance']\n",
    "            housedict['d_to_coffe'] = min(jsonf['room']['near'][2]['pois'],key = itemgetter('distance'))['distance']\n",
    "            housedict['d_to_bank'] = min(jsonf['room']['near'][3]['pois'],key = itemgetter('distance'))['distance']\n",
    "        except:\n",
    "            print 'There is no distance data'\n",
    "            housedict['metro_count'] = np.nan\n",
    "            housedict['d_to_metro'] = np.nan\n",
    "            housedict['d_to_conv'] = np.nan\n",
    "            housedict['d_to_coffe'] = np.nan\n",
    "            housedict['d_to_bank']= np.nan\n",
    "\n",
    "        try:\n",
    "            housedict['elevator'],housedict['parking'],housedict['animal'] = jsonf['room']['elevator'],jsonf['room']['parking'],jsonf['room']['animal']\n",
    "        except:\n",
    "            print 'There is no elevator and parking data'\n",
    "            housedict['elevator'],housedict['parking'] = np.nan, np.nan\n",
    "        try:\n",
    "            if jsonf['room']['maintenance']:\n",
    "                mc = jsonf['room']['maintenance_cost']\n",
    "            else: \n",
    "                mc = 0\n",
    "            if mc is None: \n",
    "                mc = 0\n",
    "            deposit = jsonf['room']['price_info'][0][0] \n",
    "            if deposit is None: \n",
    "                deposit = 0\n",
    "            rent = jsonf['room']['price_info'][0][1] \n",
    "            if rent is None :\n",
    "                rent = 0\n",
    "            price = deposit + (rent + mc) * 100\n",
    "        except:\n",
    "            print \"We can't calculate price of the house\"\n",
    "            continue\n",
    "        \n",
    "        housedict['price'] = price\n",
    "        try:\n",
    "            house_info.insert_one(housedict)\n",
    "            print 'Success'\n",
    "        except: \n",
    "            print 'fail'\n",
    "            continue\n",
    "            \n",
    "            \n",
    "            \n",
    "print 'start'    \n",
    "href_to_mongodb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We tried to add more distance data based on the location of each house by calculating distances between houses \n",
    "    * First we crawled all the addreses of starbucks and Mcdonald in Seoul from there webpages \n",
    "    * We also found the addresses of  places that possibly affect the house price by hands \n",
    "        * All the park near the Han River in Seoul\n",
    "        * 3 Luxury Good Sotres(명품관) in Seoul \n",
    "        * Myoundong Station(명동역)\n",
    "        * Gangnam Station(강남역)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7f49dc2eaacc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'http://www.mcdonalds.co.kr/www/kor/findus/district.do?pageIndex={}&sSearch_yn=Y&skey=2&skey1=&skey2=&skeyword=%EC%84%9C%EC%9A%B8&skey4=&skey5=&skeyword2=&sflag1=&sflag2=&sflag3=&sflag4=&sflag5=&sflag6=&sflag=N.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mweb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'road.*\\(?'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "#Get all the MC donald addreses in the Seoul\n",
    "for i in range(24):\n",
    "    i = i + 1\n",
    "    url = 'http://www.mcdonalds.co.kr/www/kor/findus/district.do?pageIndex={}&sSearch_yn=Y&skey=2&skey1=&skey2=&skeyword=%EC%84%9C%EC%9A%B8&skey4=&skey5=&skeyword2=&sflag1=&sflag2=&sflag3=&sflag4=&sflag5=&sflag6=&sflag=N.'.format(i)\n",
    "    web = requests.get(url)\n",
    "    x = re.findall('road.*\\(?',web.content)\n",
    "    for i in x: \n",
    "        j = re.findall('\\].+\\(',i)\n",
    "        j = re.sub('road.+\\]|\\(.+','',i)\n",
    "        lst.add(j)\n",
    "\n",
    "    \n",
    "mc_add = []\n",
    "for i,j in enumerate(lst):\n",
    "    j = j.replace('</dd>','')\n",
    "    mc_add.append(j)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get all the Starbucks address in Seoul\n",
    "chromedriver = './chromedriver'\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get('https://www.istarbucks.co.kr/store/store_map.do')\n",
    "time.sleep(6)\n",
    "local_box = driver.find_element_by_xpath(\"//header[@class = 'loca_search']\")\n",
    "local_box.click()\n",
    "time.sleep(5)\n",
    "seoul_box = driver.find_elements_by_xpath(\"//ul[@class= 'sido_arae_box']/li/a\")\n",
    "for i in seoul_box: \n",
    "    print type(i.text),i.text\n",
    "    text = unicodedata.normalize('NFC',i.text)\n",
    "    needed_text = unicodedata.normalize('NFC',u'서울')\n",
    "    if text == needed_text:\n",
    "        print 'find Seoul'\n",
    "        i.click()\n",
    "        break\n",
    "time.sleep(3)\n",
    "total_box = driver.find_elements_by_xpath(\"//a[@class = 'set_gugun_cd_btn']\")\n",
    "for i in total_box: \n",
    "    text = unicodedata.normalize('NFC',i.text)\n",
    "    needed_text = unicodedata.normalize('NFC',u'전체')\n",
    "    if text == needed_text: \n",
    "        print 'find total'\n",
    "        i.click()\n",
    "        break\n",
    "time.sleep(10)\n",
    "itemlist = driver.find_elements_by_xpath(\"//p[@class = 'result_details']\")\n",
    "html_source =driver.page_source\n",
    "addresses = re.findall('''result_details\">((?:.|\\n)*?)<br''',html_source)\n",
    "starbucks_add = addresses[10:]\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "park_add = ['서울특별시 영등포구 여의동로 330','서울특별시 영등포구 선유로 343','서울특별시 서초구 신반포로11길 40 ',\n",
    "           '서울특별시 서초구 잠원동 잠원로 26-10','서울특별시 송파구 한가람로 65','서울특별시 영등포구 당산동6가 98-1',\n",
    "           '서울특별시 광진구 강변북로 139','서울특별시 영등포구 여의동로 330','서울특별시 마포구 한강난지로 162 ',\n",
    "           '서울특별시 용산구 이촌로72길 62','서울특별시 마포구 마포나루길 467 ','서울특별시 강동구 선사로 83-66',\n",
    "           '서울특별시 강서구 방화동 2-32','']\n",
    "fancy_add = ['서울특별시 중구 남대문로 81','서울특별시 송파구 올림픽로 300','서울특별시 강남구 압구정로 343']\n",
    "myungdong_add = ['서울특별시 중구 퇴계로 126 ']\n",
    "gangnam_add = ['서울특별시 강남구 강남대로 396']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Made class to bring all the data from MongoDB to pandas dataframe style and convert addresses data to distance datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "\n",
    "class Df_converter(object):\n",
    "    \n",
    "  \n",
    "    def __init__(self):\n",
    "        mongo = MongoClient('ec2-54-149-149-184.us-west-2.compute.amazonaws.com', 27017)\n",
    "        database = mongo.dabang.room_db2\n",
    "        df = pd.DataFrame(list(database.find()))\n",
    "        df['aircondition'] = pd.Series( 1 if 0 in i   else 0 for i in df.room_options  )\n",
    "        df['laundry'] = pd.Series( 1 if 1 in i   else 0 for i in df.room_options  )\n",
    "        df['bed'] = pd.Series( 1 if 2 in i   else 0 for i in df.room_options  )\n",
    "        df['desk'] = pd.Series( 1 if 3 in i   else 0 for i in df.room_options  )\n",
    "        df['closet'] = pd.Series( 1 if 4 in i   else 0 for i in df.room_options  )\n",
    "        df['tv'] = pd.Series( 1 if 5 in i   else 0 for i in df.room_options  )\n",
    "        df['shoes'] = pd.Series( 1 if 6 in i   else 0 for i in df.room_options  )\n",
    "        df['refrigerator'] = pd.Series( 1 if 7 in i   else 0 for i in df.room_options  )\n",
    "        df['gas'] = pd.Series( 1 if 8 in i   else 0 for i in df.room_options  )\n",
    "        df['induction'] = pd.Series( 1 if 9 in i   else 0 for i in df.room_options  )\n",
    "        df['microwave'] = pd.Series( 1 if 10 in i   else 0 for i in df.room_options  )\n",
    "        df['doar_lock'] = pd.Series( 1 if 11 in i   else 0 for i in df.room_options  )\n",
    "        df['biddet'] = pd.Series( 1 if 12 in i   else 0 for i in df.room_options  )\n",
    "        df = df[(df.room_type!=u'아파트') & (df.room_type!=u'쓰리룸')] \n",
    "        df = df.drop_duplicates('id')\n",
    "        df = df.drop('_id',1)\n",
    "        self.df = df\n",
    "        self.loc=np.asarray(df['loc']).reshape(-1,1)\n",
    "     \n",
    "    \n",
    "    def location_point(self,lst):\n",
    "        loc_list = []\n",
    "        for depart in lst: \n",
    "            print 'wow'\n",
    "            try:\n",
    "                naverurl =  'https://openapi.naver.com/v1/map/geocode?encoding=utf-8&coord=latlng&output=json&query={}'.format(depart)\n",
    "                headers = {}\n",
    "                headers['X-Naver-Client-Id'] =  'Your Naver api ID'\n",
    "                headers['X-Naver-Client-Secret'] = 'Your Naver api password'\n",
    "                res = requests.get(naverurl, headers = headers)\n",
    "                jsonf = json.loads(res.content)\n",
    "                loc_list.append([float(jsonf['result']['items'][0]['point']['x']),float(jsonf['result']['items'][0]['point']['y']) ])\n",
    "            except: \n",
    "                continue\n",
    "        return loc_list\n",
    "        \n",
    "    def d_to_places(self,loc_lst):\n",
    "        \n",
    "        def dist_places(x):\n",
    "            z = []\n",
    "            for i in range(len(loc_lst)):\n",
    "                lon1, lat1, lon2, lat2 = map(radians, [x[0][0], x[0][1], loc_lst[i][0], loc_lst[i][1]])\n",
    "                dlon = lon2 - lon1 \n",
    "                dlat = lat2 - lat1 \n",
    "                a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "                c = 2 * asin(sqrt(a)) \n",
    "                km = 6367 * c\n",
    "                z.append(km)\n",
    "            return min(z)\n",
    "        return np.apply_along_axis(dist_places,1,self.loc)\n",
    "\n",
    "\n",
    "convertobj = Df_converter()\n",
    "mc_loc = convertobj.location_point(mc_address)\n",
    "star_loc = convertobj.location_point(starbucks_add)\n",
    "fancy_loc  = convertobj.location_point(fancy_add)\n",
    "myungdong_loc = convertobj.location_point(myungdong_add)\n",
    "gangnam_loc = convertobj.location_point(gangnam_add)\n",
    "park_loc = convertobj.location_point(park_add)\n",
    "df = convertobj.df\n",
    "df['d_to_fancy'] = convertobj.d_to_places(fancy_loc)\n",
    "df['park'] = convertobj.d_to_places(park_loc)\n",
    "df['distance_gn'] = convertobj.d_to_places(gangnam_loc)\n",
    "df['distance_md']= convertobj.d_to_places(myungdong_loc)\n",
    "df['d_to_mac'] = convertobj.d_to_places(mc_loc)\n",
    "df['star_bucks'] = convertobj.d_to_starbucks(star_loc)\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add the populations and elder ratio  of each 동(administrative district of Korea equivalent to town) as a new column in the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population = pd.read_csv('population.csv',encoding = 'euc-kr')\n",
    "population['population'] = [ int(''.join(i.split(','))) for i in population['population']]\n",
    "population['elder'] = [ int(''.join(i.split(','))) for i in population['elder']]\n",
    "\n",
    "popdict = {}\n",
    "elderdict ={}\n",
    "for i in range(len(population)):\n",
    "    address= u'서울특별시'+' '+ population.ix[i,:]['district'] + ' ' + population.ix[i,:]['dong']\n",
    "    popdict[address ] = population.ix[i,:]['population']\n",
    "    elderdict[address]= population.ix[i,:]['elder']\n",
    "def seriesfind(s, el):\n",
    "    for i in s.index:\n",
    "        if s[i] == el: \n",
    "            return i\n",
    "    return None\n",
    "import re\n",
    "datas = set(df['address']) - set(popdict.keys())\n",
    "for i in datas:\n",
    "    lst =  re.findall('(.+)\\d',i)\n",
    "    try:\n",
    "        addr = lst[0]\n",
    "    except:\n",
    "        continue\n",
    "    if addr in popdict.keys():\n",
    "        idx = seriesfind(df['address'],addr)\n",
    "        df['address'][idx] = addr\n",
    "pop_mean = {}\n",
    "elder_mean = {}\n",
    "popmeandf = population.groupby(['district']).mean()\n",
    "population_address = []\n",
    "elder_address =[]\n",
    "j = 0\n",
    "for i in df['address']:\n",
    "    j = j + 1\n",
    "    if j==len(df['address']):\n",
    "        break\n",
    "    try:\n",
    "        population_address.append(popdict[i])\n",
    "        elder_address.append(elderdict[i])\n",
    "    except:\n",
    "        districtlst = i.split()\n",
    "        try:\n",
    "            population_address.append(popmeandf.loc[districtlst[1]]['population'])\n",
    "            elder_address.append(popmeandf.loc[districtlst[1]]['elder'])\n",
    "        except:\n",
    "            population_address.append(np.mean(np.mean(popdict.values())))\n",
    "            elder_address.append(np.mean(np.mean(elderdict.values())))\n",
    "\n",
    "df['population'] = population_address\n",
    "df['elder'] = elder_address\n",
    "df['elder_ratio'] = np.asarray(df['elder']) / np.asarray(df['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add the number of banks in 동 to new_column in the dataframe(administrative district of Korea equivalent to town)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bank = pd.read_csv('bank.csv',encoding = 'euc-kr')\n",
    "bank['totalbanks'] = [ int(i) for i in bank['totalbanks']]\n",
    "\n",
    "bankdict = {}\n",
    "def change_add(df,key,emptydict):\n",
    "    for i in range(len(df)):\n",
    "        address= u'서울특별시'+' '+ df.ix[i,:]['district'] + ' ' + df.ix[i,:]['dong']\n",
    "        emptydict[address ] = df.ix[i,:][key]\n",
    "    return emptydict\n",
    "bankdict = change_add(bank,'totalbanks',{})\n",
    "import re\n",
    "datas = set(df['address']) - set(bankdict.keys())\n",
    "for i in datas:\n",
    "    lst =  re.findall('(.+)\\d',i)\n",
    "    try:\n",
    "        addr = lst[0]\n",
    "    except:\n",
    "        continue\n",
    "    if addr in bankdict.keys():\n",
    "        idx = seriesfind(df['address'],addr)\n",
    "        df['address'][idx] = addr\n",
    "bankmeandf = bank.groupby(['district']).mean()\n",
    "totalbanks = []\n",
    "j = 0\n",
    "for i in df['address']:\n",
    "    j = j + 1\n",
    "    if j > len(df) :\n",
    "        break\n",
    "    try:\n",
    "        totalbanks.append(bankdict[i])\n",
    "    except:\n",
    "        districtlst = i.split()\n",
    "        try:\n",
    "            totalbanks.append(bankmeandf.loc[districtlst[1]]['totalbanks'])\n",
    "        except:\n",
    "            totalbanks.append(np.mean(bankdict.values()))\n",
    "df['totalbanks'] = totalbanks\n",
    "df['bank_ratio'] = np.asarray(df['totalbanks'])/np.asarray(df['population'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
